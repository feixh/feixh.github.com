%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Medium Length Graduate Curriculum Vitae
% LaTeX Template
% Version 1.1 (9/12/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Rensselaer Polytechnic Institute (http://www.rpi.edu/dept/arc/training/latex/resumes/)
%
% Important note:
% This template requires the res.cls file to be in the same directory as the
% .tex file. The res.cls file provides the resume style used for structuring the
% document.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[margin, line, 10pt]{res} % Use the res.cls style, the font size can be changed to 11pt or 12pt here
% \topmargin=-.5in
% \marginparwidth -0.5in
\usepackage{anysize}
\marginsize{0.6in}{0.5in}{0.3in}{0.0in}

\usepackage{helvet} % Default font is the helvetica postscript font
% \usepackage{newcent} % To change the default font to the new century schoolbook postscript font uncomment this line and comment the one above
% \usepackage{times}
\usepackage[hidelinks, colorlinks=true, urlcolor=blue]{hyperref}
\usepackage{multicol}
\usepackage{tabularx}
\usepackage{enumitem}

\setlength{\textwidth}{6.1in} % Text width of the document
\newsectionwidth{1.0in}

\begin{document}

%----------------------------------------------------------------------------------------
%	NAME AND ADDRESS SECTION
%----------------------------------------------------------------------------------------

\moveleft.5\hoffset\centerline{\large\bf Xiaohan Fei} % Your name at the top

\moveleft\hoffset\vbox{\hrule width\resumewidth height 1pt}\smallskip % Horizontal line after name; adjust line thickness by changing the '1pt'
\moveleft.5\hoffset\centerline{%
% \begin{tabular}{ll}
% UCLA VisionLab, Engineering VI \#386  & Phone: (425) 240-2282\\
% University of California, Los Angeles & E-mail: feixh@cs.ucla.edu\\
% Los Angeles, CA 90095, USA & Website: \url{http://feixh.github.io}
% \end{tabular}
\begin{tabular}{ll}
    E-mail: hzhsfxh@gmail.com & Website: \url{https://feixh.github.io}
\end{tabular}
}
% \vspace{-0.3in}
%----------------------------------------------------------------------------------------
\begin{resume}

\section{\textsc{Education}}
\textsc{University of California, Los Angeles}\hfill{Sept. 2014 - Sept. 2019}\\
{\bf Ph.D. in Computer Science}\\
Research Group: UCLA Vision Lab (\url{http://vision.ucla.edu})\\
GPA: $3.88/4.0$ \\
Thesis: Inertial-aided Visual Perception of Geometry and Semantics \\
Advisor: Prof. Stefano Soatto

\textsc{Zhejiang University, Hangzhou, China}\hfill{Sept. 2010 - June 2014}\\
{\bf B.Eng. in Information and Communication Engineering}\\
Minor: Advanced honor Class of Engineering Education (ACEE), Chu-Kechen College\\
GPA: $3.98/4.0 (92.35/100)$ \\
Thesis: Wide-baseline feature matching for panoramic images\\
Thesis advisor: Prof. Zhiyu Xiang\\

% \section{\textsc{Research\\Interests}}
% My research interests lie in the intersection of computer vision, robotics, and machine learning. I develop algorithms, models, and systems to enable robots to see and understand the surrounding physical world using techniques from optimization, deep learning, and sensor fusion. Specifically, I have been working on (i) Simultaneous Localization and Mapping (SLAM) and Visual-Inertial Odometry (VIO) for robot localization, (ii) depth prediction and completion to assist robot navigation, and (iii) semantic scene understanding to enable high-level robotic tasks. My research resulted in the world's first real-time visual-inertial semantic mapping system demonstrated at CVPR 2016, and a best paper award at ICRA 2019.

% \section{\textsc{Open-source\\Software}}
% \href{https://github.com/ucla-vision/xivo}{XIVO}: a state-of-the-art localization and mapping software, forked by $100+$ and starred by $700+$ developers worldwide.
% For the rest, see my github page: \url{https://github.com/feixh}


\section{\textsc{Research\\Experience}}

\textsc{Amazon AGI, Bellevue, Washington}\hfill April 2025 - Present \\
\textbf{Principal Applied Scientist}\\ 
I'm the science lead of Amazon Nova Reel -- Amazon's foundation model for video generation launched at AWS re:Invent 2024.

\textsc{AWS AI Labs, Bellevue, Washington}\hfill April 2022 - April 2025 \\
\textbf{Senior Applied Scientist}\\ 
I led a small team working on visual and multi-sensor localization and mapping and 3-D representation learning. % We aim to push the state of the art in the field, and build products atop our research.

\textsc{AWS AI Labs, Seattle, Washington}\hfill April 2020 - March 2022 \\
\textbf{Applied Scientist}\\ 
I conducted research in the field of computer vision and machine learning, and developed cloud-based AI services. % One of my works was single view physical distance estimation which aimed to use computer vision to help slow down the spread of COVID-19, and resulted in a paper published in ICCV 2021. We are using AI to do good, and I'm very pround of this work.

\textsc{Facebook Reality Labs, Redmond, Washington}\hfill Sept. 2019 - March 2020 \\
\textbf{Research Scientist}\\
% I was a member of the Surreal team led by Dr. Richard Newcombe, and conducted research in computer vision for AR/VR.
I was a member of the Surreal team conducting research in computer vision for AR/VR.

% \textsc{NVIDIA Research, Santa Clara, California}\hfill Summer 2018\\
% \textbf{Research Intern}\\
% Conducted research in unsupervised learning of structural representation for 3-D objects.

% \textsc{Meta Company, San Mateo, California}\hfill Summer 2017\\
% \textbf{Research Intern}\\
% I worked with Dr. Karri Pulli and Dr. Timo Ahonen, and developed a tightly-coupled visual-inertial SLAM system for Meta's 2nd generation Augmented Reality headset. The system I developed is the indispensable core software component that supports all the downstream AR applications.

% \textsc{University of California, Los Angeles}\hfill Sept. 2014 - Sept. 2019\\
% \textbf{Graduate Student Researcher}\\
% Conducted research in image-based localization, visual-inertial sensor fusion, and semantic mapping.

% \textsc{Zhejiang University, China}\hfill Fall 2013 - Spring 2014\\
% \textbf{Undergraduate Thesis}\\
% Structure from Motion for panoramic video streams from a vehicle-mounted monocular camera.

% \textsc{University of California, Los Angeles}\hfill Summer 2013\\
% \textbf{Research Intern}\\
% Developed a visual recognition system on Samsung Galaxy 4 based on multi-view descriptor aggregation. Investigated ways to handle nuisance variability in feature matching and object recognition.


\section{\textsc{Awards \&\\Distinctions}}
2019: {\bf Best Paper Award} in Robot Vision, out of 2900 submissions, at ICRA 2019\\
2013: {\bf Meritorious Winner} of Mathematical Contest in Modeling (top 15\% of 6000 teams worldwide)\\
2012: {\bf National Scholarship} (the highest honor for undergraduates in China)

\section{\textsc{Publications}\\\begin{footnotesize}* indicates equal contribution\end{footnotesize}}
\begin{enumerate}[label={[\bf\arabic*]},leftmargin=*]


\item
The Amazon Nova Family of Models: Technical Report and Model Card. In \textit{arXiv}, 2024.

\item
Chethan Parameshwara$^*$, Alessandro Achille$^*$, Matthew Trager, Xiaolong Li, Jiawei Mo, Ashwin Swaminathan, CJ Taylor, Dheera Venkatraman, {\bf Xiaohan Fei}$^*$, Stefano Soatto$^*$. Towards visual foundational models of physical scenes. In \textit{arXiv}, 2023.

\item 
{\bf Xiaohan Fei}, Chethan Parameshwara, Jiawei Mo, Xiaolong Li, Ashwin Swaminathan, CJ Taylor, Paolo Favaro, Stefano Soatto. A Quantitative Evaluation of Score Distillation Sampling Based Text-to-3D. In \textit{arXiv}, 2023.

\item 
Ziqi Lu, Jianbo Ye, {\bf Xiaohan Fei}, Xiaolong Li, Jiawei Mo, Ashwin Swaminathan, Stefano Soatto.
Fast sparse view guided nerf update for object reconfigurations. In \textit{arXiv}, 2023.

\item 
Xiaolong Li, Jiawei Mo, Ying Wang, Chethan Parameshwara, {\bf Xiaohan Fei}, Ashwin Swaminathan, CJ Taylor, Zhuowen Tu, Paolo Favaro, Stefano Soatto. Grounded compositional and diverse text-to-3d with pretrained multi-view diffusion model. In \textit{arXiv}, 2023.

\item
{\bf X. Fei}, H. Wang, X. Zeng, L. Cheong, J. Tighe. Single View Physical Distance Estimation using Human Pose. In \textit{International Conference on Computer Vision} (ICCV), 2021.
\item
A. Wong, {\bf X. Fei}, B. Hong, and S. Soatto. An Adaptive Framework For Learning Unsupervised Depth Completion. In \textit{IEEE Robotics and Automation Letters} (RA-L), 2021.
\item
A. Wong$^*$, {\bf X. Fei}$^*$, and S. Soatto. Unsupervised Depth Completion from Visual-Inertial Odometry.
In \textit{International Conference on Robotics and Automation} (ICRA), 2020. Also in \textit{IEEE Robotics and Automation Letters} (RA-L).
\item 
{\bf X. Fei}, A. Wong, and S. Soatto. Geo-Supervised Visual Depth Prediction. 
In \textit{International Conference on Robotics and Automation} (ICRA), 2019. 
(\textbf{Best Paper Award in Robot Vision})
Also in \textit{IEEE Robotics and Automation Letters} (RA-L).
\item 
{\bf X. Fei}, S. Soatto. Visual-Inertial Object Detection and Mapping. 
In \textit{European Conference on Computer Vision} (ECCV), 2018.
\item 
J. Dong$^*$, {\bf X. Fei}$^*$, and S. Soatto. Visual-Inertial-Semantic Scene Representation for Object Detection. 
In \textit{Computer Vision and Pattern Recognition} (CVPR), 2017.
\item 
{\bf X. Fei}, K. Tsotsos, and S. Soatto. A Simple Hierarchical Pooling Data Structure for Loop Closure. 
In \textit{European Conference on Computer Vision} (ECCV), 2016.
\end{enumerate}

\section{\textsc{Professional\\Services}}
Reviewer of top computer vision (CVPR, ICCV, ECCV), robotics (ICRA, IROS), and artificial intelligence (AAAI) conferences.

% \section{\textsc{Talks \&\\Workshops}}
% \textit{Inertial-aided Visual Perceptionof Geometry and Semantics}, at Amazon Web Services, 2020.\\
% \textit{Inertial-aided Visual Perception for Localization, Mapping, and Detection}, at MagicLeap, Microsoft Research, Facebook Reality Labs, 2019.\\
% \textit{Visual-Inertial-Semantic Scene Representation}, at Bridges to 3D Workshop, CVPR 2017.

% \section{\textsc{Teaching}}
% CS M152A Introductory Digital Design Laboratory, Spring 2018.

\section{\textsc{Relevant\\Coursework}}
\textbf{University of California, Los Angeles:} Machine Perception (Prof. S. Soatto), Convex Optimization (Prof. L. Vandenberghe), Calculus of Variations (Prof. L. Vese), Vision as Bayesian Inference (Prof. A. Yuille), Applied Probability (Prof. Y. Wu), Theoretical Statistics (Prof. A. Amini), Numerical Analysis (Prof. J. Teran), Machine Learning Algorithm (Prof. M. Sarrafzadeh)\\
\textbf{Zhejiang University:} Computer Vision (Pof. Z. Xiang), Spectral Analysis of Signals (Prof. X. Gong), Information Theory (Prof. Z. Zhang), Mathematical Modeling (Prof. Q. Yang)

\section{\textsc{Relevant\\Skills}}
\textbf{Programming Language:} Fluent (C++, Python), Make-do (JavaScript), Collecting dust (Android, OpenGL, \textsc{Matlab})\\
\textbf{Software Framework:} Deep Learning (PyTorch, TensorFlow), Vision and Robotics (OpenCV, ROS), Math \& Optimization (Eigen, Ceres), Web (Flask, Three.js)

%----------------------------------------------------------------------------------------

\end{resume}
\end{document}
